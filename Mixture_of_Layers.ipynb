{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mixture of Layers (MoLs)"
      ],
      "metadata": {
        "id": "eAaKcrHOtKx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We propose a method for neural networks to route information dynamically through their layers in an *arbitrary order*, allowing for in-context parameter tying."
      ],
      "metadata": {
        "id": "2MpPX1tGtNNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.ibb.co/XsMYr0c/mol.png)"
      ],
      "metadata": {
        "id": "Yxaw0DEXz4l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup"
      ],
      "metadata": {
        "id": "EMfBUVKo1B-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "8qBeX90Ur-IP",
        "outputId": "4a89ea08-f060-4fda-e308-a7c9b1d805e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@markdown Install dependencies.\n",
        "\n",
        "!pip -q install transformers \\\n",
        "    diffusers \\\n",
        "    datasets \\\n",
        "    accelerate \\\n",
        "    einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LayerRouter"
      ],
      "metadata": {
        "id": "jNrra24i1DWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core of MoL is *LayerRouter*, a module that determines which layer the antecedent layer's activations should be forwarded through. Formally, LayerRouter is a function $f(\\mathbf{x}_t, t)$ given by,\n",
        "\n",
        "$$\n",
        "    f(\\mathbf{x}_t, t) = (g(\\mathbf{x}_t, t), h(\\mathbf{x}_t, t)),\n",
        "$$\n",
        "\n",
        "where $g(\\mathbf{x}_t, t)$ returns a distribution over subsequent layer indices and $h(\\mathbf{x}_t, t)$ is an arbitrary transformation on $\\mathbf{x}_t$. The subsequent layer index is chosen as $\\text{argmax}\\, g(\\mathbf{x}_t, t)$. Then, $h(\\mathbf{x}_t, t)$ is given to it as input."
      ],
      "metadata": {
        "id": "tUyKyBP41JC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Implement the router.\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"MLP.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> module = MLP(embedding_dimension=256, condition_dimension=16)\n",
        "    >>> x = torch.randn((1, 10, 256))\n",
        "    >>> c = torch.randn((16,))\n",
        "    >>> x = module(x, c)  # Shape: (1, 10, 256).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension: int,\n",
        "        condition_dimension: int,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the module.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        embedding_dimension : int\n",
        "            The embedding dimension.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                in_features=embedding_dimension + condition_dimension,\n",
        "                out_features=embedding_dimension * 3,\n",
        "            ),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(\n",
        "                in_features=embedding_dimension * 3,\n",
        "                out_features=embedding_dimension,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward the module.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The input tensor (B, T, E).\n",
        "        c : torch.Tensor\n",
        "            The condition tensor (B, C).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x : torch.Tensor\n",
        "            The output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        c = c[None, None, :].repeat((x.size(0), x.size(1), 1))  # Make `c` catable.\n",
        "        x = torch.cat((x, c), dim=-1)\n",
        "        x = self.layers(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerRouter(nn.Module):\n",
        "    \"\"\"LayerRouter.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> module = LayerRouter(\n",
        "    ...     embedding_dimension=256,\n",
        "    ...     steps=16,\n",
        "    ...     layers=(\n",
        "    ...         ...\n",
        "    ...     ),\n",
        "    ... )\n",
        "    >>> x = ...\n",
        "    >>> x = module(x)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension: int,\n",
        "        steps: int,\n",
        "        layers: Tuple[nn.Module],\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the module.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        embedding_dimension : int\n",
        "            The embedding dimension.\n",
        "        steps : int\n",
        "            The number of steps.\n",
        "        layers : int\n",
        "            The subsequent layers.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.steps = steps\n",
        "        self.layers = layers\n",
        "\n",
        "        self.mlp_1 = MLP(\n",
        "            embedding_dimension=embedding_dimension,\n",
        "            condition_dimension=steps,\n",
        "        )\n",
        "\n",
        "        self.mlp_2 = MLP(\n",
        "            embedding_dimension=embedding_dimension,\n",
        "            condition_dimension=steps,\n",
        "        )\n",
        "\n",
        "        self.head = nn.Linear(\n",
        "            in_features=embedding_dimension,\n",
        "            out_features=len(layers),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward the module.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The input tensor (B, T, E).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x : torch.Tensor\n",
        "            The output tensor (B, T, E).\n",
        "        \"\"\"\n",
        "\n",
        "        for step in torch.arange(self.steps):\n",
        "\n",
        "            condition = F.one_hot(step, num_classes=self.steps).float()\n",
        "            score = F.softmax(self.head(self.mlp_1(x, condition)), dim=-1)\n",
        "            score = score.mean(dim=-2)\n",
        "            index = (score + (score.argmax(dim=-1).view(-1, 1).detach() - score)).mean(dim=-1)  # STE.\n",
        "            x = self.mlp_2(x, condition)\n",
        "\n",
        "            # Reconstruct batch with x routed to chosen layers.\n",
        "\n",
        "            for i in range(x.size(0)):\n",
        "                index_i = int(index[i].item())\n",
        "                x[i, ...] = self.layers[index_i](x[i, ...])\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "w_xuJc9z09EU"
      },
      "execution_count": 136,
      "outputs": []
    }
  ]
}